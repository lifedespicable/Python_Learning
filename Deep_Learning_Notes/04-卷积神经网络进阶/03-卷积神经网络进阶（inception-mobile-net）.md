![1592919112714](assets/1592919112714.png)

- InceptionNet同样可以用来解决网络层次不能再加深的问题，由Google研发

![1592919237302](assets/1592919237302.png)

![1592919326621](assets/1592919326621.png)

- 更深的网络可能不仅仅是过拟合的问题，可能加深后的网络的效果还不如不加深的网络
- 稀疏网络比较类似于dropout，稀疏矩阵如果用稀疏的方式去计算会比密集矩阵用密集的方式去计算更低效

![1592920664623](assets/1592920664623.png)

![1592920676593](assets/1592920676593.png)

![1592920726794](assets/1592920726794.png)

![1592920932032](assets/1592920932032.png)

- 上图中，Kw和Kh是卷积核的宽和高（K就是Kernel的意思），Ow和Oh是输出的宽和高，Ci是输入的通道数，Co是输出的通道数，加法操作相对于乘法操作来说是可以忽略不计的

![1592921568471](assets/1592921568471.png)

![1592921649648](assets/1592921649648.png)

![1592921706473](assets/1592921706473.png)

![1592921966760](assets/1592921966760.png)

- 在V2结构中，我们使用了2个3*3去替换1个5 * 5的结构，这样可以降低参数数目，降低的幅度是28%

![1592922135929](assets/1592922135929.png)

![1592922254935](assets/1592922254935.png)

![1592922385532](assets/1592922385532.png)

- V4结构中的skip connection 其实和ResNet中的残差连接是一样的一个东西，残差连接其实就是 skip connection

![1592922554017](assets/1592922554017.png)

- MobileNet也是由Google开发的，它能保证深度损失在可控范围之内，然后可以大幅度地降低参数的数目和计算量

![1592923434759](assets/1592923434759.png)

![1592923685543](assets/1592923685543.png)

![1592923744508](assets/1592923744508.png)

![1592923830302](assets/1592923830302.png)

![1592924084064](assets/1592924084064.png)

![1592924105279](assets/1592924105279.png)

![1592924124726](assets/1592924124726.png)

- GoogleNet其实就是InceptionNet_V1

![1592924160285](assets/1592924160285.png)

- 就计算量而言，Inception_V3应该是一个比较好的拐点

![1592924192786](assets/1592924192786.png)

- 模型的对比和选择的指标应该包括计算量、模型的大小和准确率

![1592924208861](assets/1592924208861.png)

- 目前存在的最好的神经网络模型应该是NasNet

